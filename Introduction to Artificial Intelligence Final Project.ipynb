{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Artificial Intelligence Final Project\n",
    "## By Noah Segal-Gould and Tanner Cohan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To implement:\n",
    "[K-Means clustering, hierarchical document clustering, and topic modeling](http://brandonrose.org/clustering)\n",
    "\n",
    "[K-Means clustering](http://scikit-learn.org/dev/auto_examples/text/plot_document_clustering.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "from os.path import basename, splitext\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create lists of file names for all Twitter account CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "house_accounts_filenames = glob(\"house/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "senate_accounts_filenames = glob(\"senate/*.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create lists of all dataframes for all CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "house_accounts_dataframes = [pd.read_csv(filename).assign(account=\"@\" + splitext(basename(filename))[0]) \n",
    "                             for filename in house_accounts_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "senate_accounts_dataframes = [pd.read_csv(filename).assign(account=\"@\" + splitext(basename(filename))[0])\n",
    "                              for filename in senate_accounts_filenames]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find which Tweets were most Retweeted and Favorited in each list of dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "most_retweets_house_accounts_dataframes = [df.iloc[[df['Retweets'].idxmax()]] \n",
    "                                           for df in house_accounts_dataframes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "most_favorites_house_accounts_dataframes = [df.iloc[[df['Favorites'].idxmax()]] \n",
    "                                            for df in house_accounts_dataframes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "most_retweets_senate_accounts_dataframes = [df.iloc[[df['Retweets'].idxmax()]] \n",
    "                                            for df in senate_accounts_dataframes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "most_favorites_senate_accounts_dataframes = [df.iloc[[df['Favorites'].idxmax()]] \n",
    "                                             for df in senate_accounts_dataframes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataframes of the most Retweeted and Favorited Tweets for each account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "most_retweets_congress_dataframe = pd.concat(most_retweets_house_accounts_dataframes + most_retweets_senate_accounts_dataframes).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "most_favorites_congress_dataframe = pd.concat(most_favorites_house_accounts_dataframes + most_favorites_senate_accounts_dataframes).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the Retweets dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Date</th>\n",
       "      <th>Favorites</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>account</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>56 years ago today I was released from Parchma...</td>\n",
       "      <td>2017-07-07 13:17:53</td>\n",
       "      <td>259935</td>\n",
       "      <td>114910</td>\n",
       "      <td>883314124863700995</td>\n",
       "      <td>@repjohnlewis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>Retweet if you care about @realDonaldTrump's t...</td>\n",
       "      <td>2017-01-11 16:40:05</td>\n",
       "      <td>45713</td>\n",
       "      <td>123593</td>\n",
       "      <td>819222357214658561</td>\n",
       "      <td>@RonWyden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>Hey Republicans, don't worry, that burn is cov...</td>\n",
       "      <td>2017-03-24 19:53:43</td>\n",
       "      <td>310324</td>\n",
       "      <td>143726</td>\n",
       "      <td>845363015222542336</td>\n",
       "      <td>@SenatorMenendez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>It's a shame the White House has become an adu...</td>\n",
       "      <td>2017-10-08 15:13:43</td>\n",
       "      <td>419380</td>\n",
       "      <td>148639</td>\n",
       "      <td>917045348820049920</td>\n",
       "      <td>@SenBobCorker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>President Trump, you made a big mistake. By tr...</td>\n",
       "      <td>2017-01-21 22:15:24</td>\n",
       "      <td>972101</td>\n",
       "      <td>452896</td>\n",
       "      <td>822930622926745602</td>\n",
       "      <td>@SenSanders</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text                 Date  \\\n",
       "208  56 years ago today I was released from Parchma...  2017-07-07 13:17:53   \n",
       "441  Retweet if you care about @realDonaldTrump's t...  2017-01-11 16:40:05   \n",
       "469  Hey Republicans, don't worry, that burn is cov...  2017-03-24 19:53:43   \n",
       "451  It's a shame the White House has become an adu...  2017-10-08 15:13:43   \n",
       "425  President Trump, you made a big mistake. By tr...  2017-01-21 22:15:24   \n",
       "\n",
       "     Favorites  Retweets            Tweet ID           account  \n",
       "208     259935    114910  883314124863700995     @repjohnlewis  \n",
       "441      45713    123593  819222357214658561         @RonWyden  \n",
       "469     310324    143726  845363015222542336  @SenatorMenendez  \n",
       "451     419380    148639  917045348820049920     @SenBobCorker  \n",
       "425     972101    452896  822930622926745602       @SenSanders  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_retweets_congress_dataframe.sort_values('Retweets').tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the Favorites dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Date</th>\n",
       "      <th>Favorites</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>account</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>The President of the United States just defend...</td>\n",
       "      <td>2017-08-15 21:03:44</td>\n",
       "      <td>221573</td>\n",
       "      <td>82791</td>\n",
       "      <td>897564488475586560</td>\n",
       "      <td>@SenWarren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>56 years ago today I was released from Parchma...</td>\n",
       "      <td>2017-07-07 13:17:53</td>\n",
       "      <td>259935</td>\n",
       "      <td>114910</td>\n",
       "      <td>883314124863700995</td>\n",
       "      <td>@repjohnlewis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>Hey Republicans, don't worry, that burn is cov...</td>\n",
       "      <td>2017-03-24 19:53:43</td>\n",
       "      <td>310324</td>\n",
       "      <td>143726</td>\n",
       "      <td>845363015222542336</td>\n",
       "      <td>@SenatorMenendez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>It's a shame the White House has become an adu...</td>\n",
       "      <td>2017-10-08 15:13:43</td>\n",
       "      <td>419380</td>\n",
       "      <td>148639</td>\n",
       "      <td>917045348820049920</td>\n",
       "      <td>@SenBobCorker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>President Trump, you made a big mistake. By tr...</td>\n",
       "      <td>2017-01-21 22:15:24</td>\n",
       "      <td>972101</td>\n",
       "      <td>452896</td>\n",
       "      <td>822930622926745602</td>\n",
       "      <td>@SenSanders</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text                 Date  \\\n",
       "453  The President of the United States just defend...  2017-08-15 21:03:44   \n",
       "208  56 years ago today I was released from Parchma...  2017-07-07 13:17:53   \n",
       "469  Hey Republicans, don't worry, that burn is cov...  2017-03-24 19:53:43   \n",
       "451  It's a shame the White House has become an adu...  2017-10-08 15:13:43   \n",
       "425  President Trump, you made a big mistake. By tr...  2017-01-21 22:15:24   \n",
       "\n",
       "     Favorites  Retweets            Tweet ID           account  \n",
       "453     221573     82791  897564488475586560        @SenWarren  \n",
       "208     259935    114910  883314124863700995     @repjohnlewis  \n",
       "469     310324    143726  845363015222542336  @SenatorMenendez  \n",
       "451     419380    148639  917045348820049920     @SenBobCorker  \n",
       "425     972101    452896  822930622926745602       @SenSanders  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_favorites_congress_dataframe.sort_values('Favorites').tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine all House of Representatives' accounts, all Senators' accounts, and then combine them together into all Congress accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "house_dataframe = pd.concat(house_accounts_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "senate_dataframe = pd.concat(senate_accounts_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress_dataframe = pd.concat([house_dataframe, senate_dataframe]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove columns with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "congress_dataframe.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print some statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Tweets for all accounts: 1614705\n",
      "Total number of accounts: 524\n",
      "Total number of house members: 424\n",
      "Total number of senators: 100\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of Tweets for all accounts: \" + str(len(congress_dataframe)))\n",
    "print(\"Total number of accounts: \" + str(len(set(congress_dataframe[\"account\"]))))\n",
    "print(\"Total number of house members: \" + str(len(set(house_dataframe[\"account\"]))))\n",
    "print(\"Total number of senators: \" + str(len(set(senate_dataframe[\"account\"]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get NLTK English stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate SnowballStemmer as stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load NLTK's Tweet Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a function to return the list of stemmed words and the list of tokens which have been stripped of non-alphabetical characters and stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_and_stem(text):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    filtered_tokens = [word for word in tokens if (word.isalpha() and word not in stopwords)]\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems\n",
    "\n",
    "def tokenize_only(text):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    filtered_tokens = [word for word in tokens if (word.isalpha() and word not in stopwords)]\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a function for getting lists of stemmed and tokenized Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stemmed_and_tokenized_dict(tweets):\n",
    "    stemmed = []\n",
    "    tokenized = []\n",
    "    for tweet in tweets:\n",
    "        stemmed.extend(tokenize_and_stem(tweet))\n",
    "        tokenized.extend(tokenize_only(tweet))\n",
    "    return {\"Stemmed\": stemmed, \"Tokenized\": tokenized}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply function to Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 44s, sys: 10.8 s, total: 13min 54s\n",
      "Wall time: 14min 43s\n"
     ]
    }
   ],
   "source": [
    "%time stemmed_and_tokenized_dict = get_stemmed_and_tokenized_dict(congress_dataframe[\"Text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a dataframe of stemmed and tokenized words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_frame = pd.DataFrame({'words': stemmed_and_tokenized_dict[\"Tokenized\"]}, \n",
    "                           index = stemmed_and_tokenized_dict[\"Stemmed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 15053531 items in vocab_frame\n"
     ]
    }
   ],
   "source": [
    "print(\"There are \" + str(vocab_frame.shape[0]) + \" items in vocab_frame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>truli</th>\n",
       "      <td>Truly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unfortun</th>\n",
       "      <td>unfortunate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>democrat</th>\n",
       "      <td>Democrats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distort</th>\n",
       "      <td>distorting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attorney</th>\n",
       "      <td>Attorney</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                words\n",
       "truli           Truly\n",
       "unfortun  unfortunate\n",
       "democrat    Democrats\n",
       "distort    distorting\n",
       "attorney     Attorney"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_frame.to_csv(\"vocab_frame.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up TF-IDF vectorizer from Scikit Learn and also apply the vectorizer to the Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.5, max_features=2000,\n",
    "                                   min_df=2, stop_words='english',\n",
    "                                   use_idf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57.8 s, sys: 5.53 s, total: 1min 3s\n",
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "%time tfidf_matrix = tfidf_vectorizer.fit_transform(congress_dataframe[\"Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1614705, 2000)\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "terms = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dist = 1 - cosine_similarity(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up K-Means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#num_clusters = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#km = KMeans(n_clusters=num_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%time km.fit(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternatively use K-Means++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_clusters = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=num_clusters, init='k-means++', max_iter=100, n_init=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%time km.fit(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the top 10 keywords for each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "for i in range(num_clusters):\n",
    "    print(\"Cluster %d:\" % i, end=\" \")\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(\" %s\" % terms[ind], end=\" \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
