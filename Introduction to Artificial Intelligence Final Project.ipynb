{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Artificial Intelligence Final Project\n",
    "## By Noah Segal-Gould and Tanner Cohan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To implement:\n",
    "[This article](http://brandonrose.org/clustering)\n",
    "\n",
    "[Modified version of above](https://github.com/toyota790/Twitter_PanamaPapers_Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from glob import glob\n",
    "from os.path import basename, splitext\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create lists of file names for all Twitter account CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "house_accounts_filenames = glob(\"house/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "senate_accounts_filenames = glob(\"senate/*.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create lists of all dataframes for all CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "house_accounts_dataframes = [pd.read_csv(filename).assign(account=\"@\" + splitext(basename(filename))[0]) \n",
    "                             for filename in house_accounts_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "senate_accounts_dataframes = [pd.read_csv(filename).assign(account=\"@\" + splitext(basename(filename))[0])\n",
    "                              for filename in senate_accounts_filenames]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find which 10 Tweets were most Retweeted and Favorited in each list of dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_retweets_house_accounts_dataframes = [df.sort_values('Retweets').tail(25)\n",
    "                                           for df in house_accounts_dataframes]\n",
    "#[df.iloc[[df['Retweets'].idxmax()]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "most_favorites_house_accounts_dataframes = [df.sort_values('Favorites').tail(25)\n",
    "                                            for df in house_accounts_dataframes]\n",
    "#[df.iloc[[df['Favorites'].idxmax()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "most_retweets_senate_accounts_dataframes = [df.sort_values('Retweets').tail(25)\n",
    "                                            for df in senate_accounts_dataframes]\n",
    "#[df.iloc[[df['Retweets'].idxmax()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "most_favorites_senate_accounts_dataframes = [df.sort_values('Favorites').tail(25)\n",
    "                                             for df in senate_accounts_dataframes]\n",
    "#[df.iloc[[df['Favorites'].idxmax()]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataframes of the most Retweeted and Favorited Tweets for each account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "most_retweets_congress_dataframe = pd.concat(most_retweets_house_accounts_dataframes + most_retweets_senate_accounts_dataframes).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "most_favorites_congress_dataframe = pd.concat(most_favorites_house_accounts_dataframes + most_favorites_senate_accounts_dataframes).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the Retweets dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Date</th>\n",
       "      <th>Favorites</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>account</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11726</th>\n",
       "      <td>Hey Republicans, don't worry, that burn is cov...</td>\n",
       "      <td>2017-03-24 19:53:43</td>\n",
       "      <td>310324</td>\n",
       "      <td>143726</td>\n",
       "      <td>845363015222542336</td>\n",
       "      <td>@SenatorMenendez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11276</th>\n",
       "      <td>It's a shame the White House has become an adu...</td>\n",
       "      <td>2017-10-08 15:13:43</td>\n",
       "      <td>419380</td>\n",
       "      <td>148639</td>\n",
       "      <td>917045348820049920</td>\n",
       "      <td>@SenBobCorker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10624</th>\n",
       "      <td>.@realDonaldTrump, you are embarrassing our co...</td>\n",
       "      <td>2017-08-15 22:06:45</td>\n",
       "      <td>562982</td>\n",
       "      <td>199780</td>\n",
       "      <td>897580346379829250</td>\n",
       "      <td>@SenSanders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10625</th>\n",
       "      <td>.@realDonaldTrump They did. It wasn't.pic.twit...</td>\n",
       "      <td>2017-02-25 13:56:12</td>\n",
       "      <td>518361</td>\n",
       "      <td>206269</td>\n",
       "      <td>835488569850494976</td>\n",
       "      <td>@SenSanders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10626</th>\n",
       "      <td>President Trump, you made a big mistake. By tr...</td>\n",
       "      <td>2017-01-21 22:15:24</td>\n",
       "      <td>972101</td>\n",
       "      <td>452896</td>\n",
       "      <td>822930622926745602</td>\n",
       "      <td>@SenSanders</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text                 Date  \\\n",
       "11726  Hey Republicans, don't worry, that burn is cov...  2017-03-24 19:53:43   \n",
       "11276  It's a shame the White House has become an adu...  2017-10-08 15:13:43   \n",
       "10624  .@realDonaldTrump, you are embarrassing our co...  2017-08-15 22:06:45   \n",
       "10625  .@realDonaldTrump They did. It wasn't.pic.twit...  2017-02-25 13:56:12   \n",
       "10626  President Trump, you made a big mistake. By tr...  2017-01-21 22:15:24   \n",
       "\n",
       "       Favorites  Retweets            Tweet ID           account  \n",
       "11726     310324    143726  845363015222542336  @SenatorMenendez  \n",
       "11276     419380    148639  917045348820049920     @SenBobCorker  \n",
       "10624     562982    199780  897580346379829250       @SenSanders  \n",
       "10625     518361    206269  835488569850494976       @SenSanders  \n",
       "10626     972101    452896  822930622926745602       @SenSanders  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_retweets_congress_dataframe.sort_values('Retweets').tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the Favorites dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Date</th>\n",
       "      <th>Favorites</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>account</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11726</th>\n",
       "      <td>Hey Republicans, don't worry, that burn is cov...</td>\n",
       "      <td>2017-03-24 19:53:43</td>\n",
       "      <td>310324</td>\n",
       "      <td>143726</td>\n",
       "      <td>845363015222542336</td>\n",
       "      <td>@SenatorMenendez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11276</th>\n",
       "      <td>It's a shame the White House has become an adu...</td>\n",
       "      <td>2017-10-08 15:13:43</td>\n",
       "      <td>419380</td>\n",
       "      <td>148639</td>\n",
       "      <td>917045348820049920</td>\n",
       "      <td>@SenBobCorker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10624</th>\n",
       "      <td>.@realDonaldTrump They did. It wasn't.pic.twit...</td>\n",
       "      <td>2017-02-25 13:56:12</td>\n",
       "      <td>518361</td>\n",
       "      <td>206269</td>\n",
       "      <td>835488569850494976</td>\n",
       "      <td>@SenSanders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10625</th>\n",
       "      <td>.@realDonaldTrump, you are embarrassing our co...</td>\n",
       "      <td>2017-08-15 22:06:45</td>\n",
       "      <td>562982</td>\n",
       "      <td>199780</td>\n",
       "      <td>897580346379829250</td>\n",
       "      <td>@SenSanders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10626</th>\n",
       "      <td>President Trump, you made a big mistake. By tr...</td>\n",
       "      <td>2017-01-21 22:15:24</td>\n",
       "      <td>972101</td>\n",
       "      <td>452896</td>\n",
       "      <td>822930622926745602</td>\n",
       "      <td>@SenSanders</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text                 Date  \\\n",
       "11726  Hey Republicans, don't worry, that burn is cov...  2017-03-24 19:53:43   \n",
       "11276  It's a shame the White House has become an adu...  2017-10-08 15:13:43   \n",
       "10624  .@realDonaldTrump They did. It wasn't.pic.twit...  2017-02-25 13:56:12   \n",
       "10625  .@realDonaldTrump, you are embarrassing our co...  2017-08-15 22:06:45   \n",
       "10626  President Trump, you made a big mistake. By tr...  2017-01-21 22:15:24   \n",
       "\n",
       "       Favorites  Retweets            Tweet ID           account  \n",
       "11726     310324    143726  845363015222542336  @SenatorMenendez  \n",
       "11276     419380    148639  917045348820049920     @SenBobCorker  \n",
       "10624     518361    206269  835488569850494976       @SenSanders  \n",
       "10625     562982    199780  897580346379829250       @SenSanders  \n",
       "10626     972101    452896  822930622926745602       @SenSanders  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_favorites_congress_dataframe.sort_values('Favorites').tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine all House of Representatives' accounts, all Senators' accounts, and then combine them together into all Congress accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "house_dataframe = pd.concat(house_accounts_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "senate_dataframe = pd.concat(senate_accounts_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "congress_dataframe = pd.concat([house_dataframe, senate_dataframe]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove columns with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "congress_dataframe.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print some statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Tweets for all accounts: 1614705\n",
      "Total number of accounts: 524\n",
      "Total number of house members: 424\n",
      "Total number of senators: 100\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of Tweets for all accounts: \" + str(len(congress_dataframe)))\n",
    "print(\"Total number of accounts: \" + str(len(set(congress_dataframe[\"account\"]))))\n",
    "print(\"Total number of house members: \" + str(len(set(house_dataframe[\"account\"]))))\n",
    "print(\"Total number of senators: \" + str(len(set(senate_dataframe[\"account\"]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get NLTK English stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate SnowballStemmer as stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load NLTK's Tweet Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a function to remove hashtags, mentions, and URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_word(word):\n",
    "    return all([(\"#\" not in word), \n",
    "                (\"@\" not in word), \n",
    "                (\".\" not in word), \n",
    "                (word.isalpha()), \n",
    "                (word not in stopwords)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a function to return the list of stemmed words and the list of tokens which have been stripped of non-alphabetical characters and stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_and_stem(text):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    filtered_tokens = [word for word in tokens if clean_word(word)]\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems\n",
    "\n",
    "def tokenize_only(text):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    filtered_tokens = [word.lower() for word in tokens if clean_word(word)]\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a function for getting lists of stemmed and tokenized Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stemmed_and_tokenized_dict(tweets):\n",
    "    stemmed = []\n",
    "    tokenized = []\n",
    "    for tweet in tweets:\n",
    "        stemmed.extend(tokenize_and_stem(tweet))\n",
    "        tokenized.extend(tokenize_only(tweet))\n",
    "    return {\"Stemmed\": stemmed, \"Tokenized\": tokenized}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply function to Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.19 s, sys: 94.3 ms, total: 8.28 s\n",
      "Wall time: 8.41 s\n"
     ]
    }
   ],
   "source": [
    "%time stemmed_and_tokenized_dict = get_stemmed_and_tokenized_dict(most_favorites_congress_dataframe[\"Text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a dataframe of stemmed and tokenized words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_frame = pd.DataFrame({'words': stemmed_and_tokenized_dict[\"Tokenized\"]}, \n",
    "                           index = stemmed_and_tokenized_dict[\"Stemmed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 133507 items in vocab_frame\n"
     ]
    }
   ],
   "source": [
    "print(\"There are \" + str(vocab_frame.shape[0]) + \" items in vocab_frame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>congrat</th>\n",
       "      <td>congrats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump</th>\n",
       "      <td>trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>make</th>\n",
       "      <td>making</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deal</th>\n",
       "      <td>deal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get</th>\n",
       "      <td>gets</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            words\n",
       "congrat  congrats\n",
       "trump       trump\n",
       "make       making\n",
       "deal         deal\n",
       "get          gets"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up TF-IDF vectorizer from Scikit Learn and also apply the vectorizer to the Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.5, sublinear_tf=True,\n",
    "                                   min_df=0.001, stop_words='english',\n",
    "                                   use_idf=True, tokenizer=tokenize_and_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.8 s, sys: 64.5 ms, total: 5.86 s\n",
      "Wall time: 5.92 s\n"
     ]
    }
   ],
   "source": [
    "%time tfidf_matrix = tfidf_vectorizer.fit_transform(most_favorites_congress_dataframe[\"Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13077, 1398)\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "terms = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dist = 1 - cosine_similarity(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up K-Means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_clusters = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=num_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.3 s, sys: 195 ms, total: 15.5 s\n",
      "Wall time: 16.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=5, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time km.fit(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternatively use K-Means++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#num_clusters = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#km = KMeans(n_clusters=num_clusters, init='k-means++', max_iter=100, n_init=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%time km.fit(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save/load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['doc_cluster.pkl']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(km, 'doc_cluster.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#km = joblib.load('doc_cluster.pkl')\n",
    "#clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create new dataframe for easy access of accounts which apply to clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets = {'Account': most_favorites_congress_dataframe[\"account\"], \n",
    "          'Text': most_favorites_congress_dataframe[\"Text\"], \n",
    "          'cluster': clusters}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame = pd.DataFrame(tweets, columns = ['Account', 'Text', 'cluster'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Tweets per cluster (clusters from 0 to 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    8693\n",
       "3    1306\n",
       "1    1303\n",
       "0    1086\n",
       "2     689\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the top 10 keywords and the accounts for each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_n_words = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_n_accounts = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms and accounts per cluster:\n",
      "\n",
      "Cluster 1 words: american, people, deserve, tax, health, millions, care, act, voted, today\n",
      "Cluster 1 top 5 accounts: @RepMcGovern, @RepWalorski, @MikeKellyPA, @RepBarragan, @Jim_Jordan\n",
      "\n",
      "Cluster 2 words: voted, house, floor, passed, today, gun, white, senator, act, colleagues\n",
      "Cluster 2 top 5 accounts: @RepJohnDelaney, @RepTomGraves, @RepEdRoyce, @RepJBridenstine, @RepJohnLarson\n",
      "\n",
      "Cluster 3 words: thank, today, served, work, service, honoring, great, happy, day, office\n",
      "Cluster 3 top 5 accounts: @MaxineWaters, @SanfordBishop, @RepJenniffer, @RepChuck, @RepDennisRoss\n",
      "\n",
      "Cluster 4 words: president, trump, great, mr, today, meet, news, statement, making, happy\n",
      "Cluster 4 top 5 accounts: @RepAlGreen, @RepAdamSchiff, @SenSanders, @RepDonaldPayne, @RepKarenBass\n",
      "\n",
      "Cluster 5 words: today, need, proud, work, stand, support, family, joining, w, tax\n",
      "Cluster 5 top 5 accounts: @RepRWilliams, @RepAndyBiggsAZ, @RepBrianFitz, @RepRaskin, @SenAlexander\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Top terms and accounts per cluster:\")\n",
    "print()\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1] \n",
    "for i in range(num_clusters):\n",
    "    print(\"Cluster %s words: \" % str(i+1) + \", \".join([vocab_frame.loc[terms[ind].split(' ')].values.tolist()[0][0] \n",
    "                                                      for ind in order_centroids[i, :top_n_words]]))\n",
    "    print(\"Cluster \" + str(i+1) + \" top \" + str(top_n_accounts) + \" accounts: \", end='')\n",
    "    print(\", \".join([account for account, value in Counter(frame[frame[\"cluster\"] == i][\"Account\"]).most_common(top_n_accounts)]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
